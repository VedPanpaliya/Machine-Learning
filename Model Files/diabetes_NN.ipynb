{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b2ac36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09959f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0              6      148             72             35        0  33.6   \n",
       "1              1       85             66             29        0  26.6   \n",
       "2              8      183             64              0        0  23.3   \n",
       "3              1       89             66             23       94  28.1   \n",
       "4              0      137             40             35      168  43.1   \n",
       "..           ...      ...            ...            ...      ...   ...   \n",
       "763           10      101             76             48      180  32.9   \n",
       "764            2      122             70             27        0  36.8   \n",
       "765            5      121             72             23      112  26.2   \n",
       "766            1      126             60              0        0  30.1   \n",
       "767            1       93             70             31        0  30.4   \n",
       "\n",
       "     DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                       0.627   50        1  \n",
       "1                       0.351   31        0  \n",
       "2                       0.672   32        1  \n",
       "3                       0.167   21        0  \n",
       "4                       2.288   33        1  \n",
       "..                        ...  ...      ...  \n",
       "763                     0.171   63        0  \n",
       "764                     0.340   27        0  \n",
       "765                     0.245   30        0  \n",
       "766                     0.349   47        1  \n",
       "767                     0.315   23        0  \n",
       "\n",
       "[768 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv(\"C:\\\\Users\\\\win10\\\\OneDrive\\\\Desktop\\\\DNN Project\\\\datasets\\\\diabetes.csv\")\n",
    "diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcd849dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6adc846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    268\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes['Outcome'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d279340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.298000</td>\n",
       "      <td>109.980000</td>\n",
       "      <td>68.184000</td>\n",
       "      <td>19.664000</td>\n",
       "      <td>68.792000</td>\n",
       "      <td>30.304200</td>\n",
       "      <td>0.429734</td>\n",
       "      <td>31.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.865672</td>\n",
       "      <td>141.257463</td>\n",
       "      <td>70.824627</td>\n",
       "      <td>22.164179</td>\n",
       "      <td>100.335821</td>\n",
       "      <td>35.142537</td>\n",
       "      <td>0.550500</td>\n",
       "      <td>37.067164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "Outcome                                                                      \n",
       "0           3.298000  109.980000      68.184000      19.664000   68.792000   \n",
       "1           4.865672  141.257463      70.824627      22.164179  100.335821   \n",
       "\n",
       "               BMI  DiabetesPedigreeFunction        Age  \n",
       "Outcome                                                  \n",
       "0        30.304200                  0.429734  31.190000  \n",
       "1        35.142537                  0.550500  37.067164  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.groupby('Outcome').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3793040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train_data = diabetes.sample(frac=0.8, random_state=101)\n",
    "val_data = diabetes.drop(train_data.index).sample(frac=0.5, random_state=101)\n",
    "test_data = diabetes.drop(train_data.index).drop(val_data.index)\n",
    "\n",
    "# Split features and labels\n",
    "train_labels = train_data.pop('Outcome')\n",
    "val_labels = val_data.pop('Outcome')\n",
    "test_labels = test_data.pop('Outcome')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "81080210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "# model = keras.Sequential([\n",
    "#     keras.layers.Dense(1, input_shape=[8], activation='sigmoid')\n",
    "# ])\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Dense(16, input_shape=[8], activation='relu'))\n",
    "# model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(8, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3fbe872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "optimize = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=optimize, loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88bce2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "20/20 [==============================] - 5s 46ms/step - loss: 0.6470 - accuracy: 0.6531 - val_loss: 0.6879 - val_accuracy: 0.5844\n",
      "Epoch 2/256\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6864 - val_accuracy: 0.5844\n",
      "Epoch 3/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6858 - val_accuracy: 0.5844\n",
      "Epoch 4/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6461 - accuracy: 0.6531 - val_loss: 0.6861 - val_accuracy: 0.5844\n",
      "Epoch 5/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6870 - val_accuracy: 0.5844\n",
      "Epoch 6/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 7/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6900 - val_accuracy: 0.5844\n",
      "Epoch 8/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6888 - val_accuracy: 0.5844\n",
      "Epoch 9/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 10/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 11/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6889 - val_accuracy: 0.5844\n",
      "Epoch 12/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6885 - val_accuracy: 0.5844\n",
      "Epoch 13/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6876 - val_accuracy: 0.5844\n",
      "Epoch 14/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6870 - val_accuracy: 0.5844\n",
      "Epoch 15/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6877 - val_accuracy: 0.5844\n",
      "Epoch 16/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6870 - val_accuracy: 0.5844\n",
      "Epoch 17/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6461 - accuracy: 0.6531 - val_loss: 0.6869 - val_accuracy: 0.5844\n",
      "Epoch 18/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6894 - val_accuracy: 0.5844\n",
      "Epoch 19/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6895 - val_accuracy: 0.5844\n",
      "Epoch 20/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6879 - val_accuracy: 0.5844\n",
      "Epoch 21/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6872 - val_accuracy: 0.5844\n",
      "Epoch 22/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6463 - accuracy: 0.6531 - val_loss: 0.6904 - val_accuracy: 0.5844\n",
      "Epoch 23/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6900 - val_accuracy: 0.5844\n",
      "Epoch 24/256\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6904 - val_accuracy: 0.5844\n",
      "Epoch 25/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6909 - val_accuracy: 0.5844\n",
      "Epoch 26/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 27/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6899 - val_accuracy: 0.5844\n",
      "Epoch 28/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6894 - val_accuracy: 0.5844\n",
      "Epoch 29/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6894 - val_accuracy: 0.5844\n",
      "Epoch 30/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6905 - val_accuracy: 0.5844\n",
      "Epoch 31/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6912 - val_accuracy: 0.5844\n",
      "Epoch 32/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6907 - val_accuracy: 0.5844\n",
      "Epoch 33/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6916 - val_accuracy: 0.5844\n",
      "Epoch 34/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6900 - val_accuracy: 0.5844\n",
      "Epoch 35/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6895 - val_accuracy: 0.5844\n",
      "Epoch 36/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6892 - val_accuracy: 0.5844\n",
      "Epoch 37/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6895 - val_accuracy: 0.5844\n",
      "Epoch 38/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6911 - val_accuracy: 0.5844\n",
      "Epoch 39/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6888 - val_accuracy: 0.5844\n",
      "Epoch 40/256\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6869 - val_accuracy: 0.5844\n",
      "Epoch 41/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6881 - val_accuracy: 0.5844\n",
      "Epoch 42/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 43/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6897 - val_accuracy: 0.5844\n",
      "Epoch 44/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6891 - val_accuracy: 0.5844\n",
      "Epoch 45/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6880 - val_accuracy: 0.5844\n",
      "Epoch 46/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 47/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 48/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6887 - val_accuracy: 0.5844\n",
      "Epoch 49/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6887 - val_accuracy: 0.5844\n",
      "Epoch 50/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6885 - val_accuracy: 0.5844\n",
      "Epoch 51/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6897 - val_accuracy: 0.5844\n",
      "Epoch 52/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6910 - val_accuracy: 0.5844\n",
      "Epoch 53/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6908 - val_accuracy: 0.5844\n",
      "Epoch 54/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6908 - val_accuracy: 0.5844\n",
      "Epoch 55/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6927 - val_accuracy: 0.5844\n",
      "Epoch 56/256\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6924 - val_accuracy: 0.5844\n",
      "Epoch 57/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6900 - val_accuracy: 0.5844\n",
      "Epoch 58/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6880 - val_accuracy: 0.5844\n",
      "Epoch 59/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6870 - val_accuracy: 0.5844\n",
      "Epoch 60/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 61/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6879 - val_accuracy: 0.5844\n",
      "Epoch 62/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6871 - val_accuracy: 0.5844\n",
      "Epoch 63/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6894 - val_accuracy: 0.5844\n",
      "Epoch 64/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6868 - val_accuracy: 0.5844\n",
      "Epoch 65/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6869 - val_accuracy: 0.5844\n",
      "Epoch 66/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 67/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6879 - val_accuracy: 0.5844\n",
      "Epoch 68/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 69/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6901 - val_accuracy: 0.5844\n",
      "Epoch 70/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6905 - val_accuracy: 0.5844\n",
      "Epoch 71/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6904 - val_accuracy: 0.5844\n",
      "Epoch 72/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6886 - val_accuracy: 0.5844\n",
      "Epoch 73/256\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6884 - val_accuracy: 0.5844\n",
      "Epoch 74/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 75/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 76/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6886 - val_accuracy: 0.5844\n",
      "Epoch 77/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6887 - val_accuracy: 0.5844\n",
      "Epoch 78/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6466 - accuracy: 0.6531 - val_loss: 0.6858 - val_accuracy: 0.5844\n",
      "Epoch 79/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6877 - val_accuracy: 0.5844\n",
      "Epoch 80/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 81/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 82/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6880 - val_accuracy: 0.5844\n",
      "Epoch 83/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6866 - val_accuracy: 0.5844\n",
      "Epoch 84/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6461 - accuracy: 0.6531 - val_loss: 0.6861 - val_accuracy: 0.5844\n",
      "Epoch 85/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 86/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6900 - val_accuracy: 0.5844\n",
      "Epoch 87/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 88/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6900 - val_accuracy: 0.5844\n",
      "Epoch 89/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6889 - val_accuracy: 0.5844\n",
      "Epoch 90/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6874 - val_accuracy: 0.5844\n",
      "Epoch 91/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6897 - val_accuracy: 0.5844\n",
      "Epoch 92/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6884 - val_accuracy: 0.5844\n",
      "Epoch 93/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6885 - val_accuracy: 0.5844\n",
      "Epoch 94/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6874 - val_accuracy: 0.5844\n",
      "Epoch 95/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6870 - val_accuracy: 0.5844\n",
      "Epoch 96/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 97/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6901 - val_accuracy: 0.5844\n",
      "Epoch 98/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6897 - val_accuracy: 0.5844\n",
      "Epoch 99/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6911 - val_accuracy: 0.5844\n",
      "Epoch 100/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6461 - accuracy: 0.6531 - val_loss: 0.6921 - val_accuracy: 0.5844\n",
      "Epoch 101/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6891 - val_accuracy: 0.5844\n",
      "Epoch 102/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6898 - val_accuracy: 0.5844\n",
      "Epoch 103/256\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6890 - val_accuracy: 0.5844\n",
      "Epoch 104/256\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6878 - val_accuracy: 0.5844\n",
      "Epoch 105/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6878 - val_accuracy: 0.5844\n",
      "Epoch 106/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6884 - val_accuracy: 0.5844\n",
      "Epoch 107/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6875 - val_accuracy: 0.5844\n",
      "Epoch 108/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6879 - val_accuracy: 0.5844\n",
      "Epoch 109/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6886 - val_accuracy: 0.5844\n",
      "Epoch 110/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6888 - val_accuracy: 0.5844\n",
      "Epoch 111/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6876 - val_accuracy: 0.5844\n",
      "Epoch 112/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6884 - val_accuracy: 0.5844\n",
      "Epoch 113/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 114/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6918 - val_accuracy: 0.5844\n",
      "Epoch 115/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6909 - val_accuracy: 0.5844\n",
      "Epoch 116/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6891 - val_accuracy: 0.5844\n",
      "Epoch 117/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6895 - val_accuracy: 0.5844\n",
      "Epoch 118/256\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6892 - val_accuracy: 0.5844\n",
      "Epoch 119/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6890 - val_accuracy: 0.5844\n",
      "Epoch 120/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6881 - val_accuracy: 0.5844\n",
      "Epoch 121/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6868 - val_accuracy: 0.5844\n",
      "Epoch 122/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6877 - val_accuracy: 0.5844\n",
      "Epoch 123/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 124/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6884 - val_accuracy: 0.5844\n",
      "Epoch 125/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6873 - val_accuracy: 0.5844\n",
      "Epoch 126/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6887 - val_accuracy: 0.5844\n",
      "Epoch 127/256\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 128/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6902 - val_accuracy: 0.5844\n",
      "Epoch 129/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 130/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6917 - val_accuracy: 0.5844\n",
      "Epoch 131/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6888 - val_accuracy: 0.5844\n",
      "Epoch 132/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6895 - val_accuracy: 0.5844\n",
      "Epoch 133/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 134/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 135/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6867 - val_accuracy: 0.5844\n",
      "Epoch 136/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6852 - val_accuracy: 0.5844\n",
      "Epoch 137/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6869 - val_accuracy: 0.5844\n",
      "Epoch 138/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6462 - accuracy: 0.6531 - val_loss: 0.6862 - val_accuracy: 0.5844\n",
      "Epoch 139/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6867 - val_accuracy: 0.5844\n",
      "Epoch 140/256\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 141/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6890 - val_accuracy: 0.5844\n",
      "Epoch 142/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6890 - val_accuracy: 0.5844\n",
      "Epoch 143/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 144/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6873 - val_accuracy: 0.5844\n",
      "Epoch 145/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6875 - val_accuracy: 0.5844\n",
      "Epoch 146/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6884 - val_accuracy: 0.5844\n",
      "Epoch 147/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 148/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6887 - val_accuracy: 0.5844\n",
      "Epoch 149/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6876 - val_accuracy: 0.5844\n",
      "Epoch 150/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6881 - val_accuracy: 0.5844\n",
      "Epoch 151/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6874 - val_accuracy: 0.5844\n",
      "Epoch 152/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6878 - val_accuracy: 0.5844\n",
      "Epoch 153/256\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6890 - val_accuracy: 0.5844\n",
      "Epoch 154/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6901 - val_accuracy: 0.5844\n",
      "Epoch 155/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6894 - val_accuracy: 0.5844\n",
      "Epoch 156/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 157/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6899 - val_accuracy: 0.5844\n",
      "Epoch 158/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6885 - val_accuracy: 0.5844\n",
      "Epoch 159/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6891 - val_accuracy: 0.5844\n",
      "Epoch 160/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6878 - val_accuracy: 0.5844\n",
      "Epoch 161/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6899 - val_accuracy: 0.5844\n",
      "Epoch 162/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6894 - val_accuracy: 0.5844\n",
      "Epoch 163/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6460 - accuracy: 0.6531 - val_loss: 0.6874 - val_accuracy: 0.5844\n",
      "Epoch 164/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6886 - val_accuracy: 0.5844\n",
      "Epoch 165/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6894 - val_accuracy: 0.5844\n",
      "Epoch 166/256\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 167/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6897 - val_accuracy: 0.5844\n",
      "Epoch 168/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6922 - val_accuracy: 0.5844\n",
      "Epoch 169/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6918 - val_accuracy: 0.5844\n",
      "Epoch 170/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6904 - val_accuracy: 0.5844\n",
      "Epoch 171/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6904 - val_accuracy: 0.5844\n",
      "Epoch 172/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6912 - val_accuracy: 0.5844\n",
      "Epoch 173/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6912 - val_accuracy: 0.5844\n",
      "Epoch 174/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6909 - val_accuracy: 0.5844\n",
      "Epoch 175/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6909 - val_accuracy: 0.5844\n",
      "Epoch 176/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6911 - val_accuracy: 0.5844\n",
      "Epoch 177/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6921 - val_accuracy: 0.5844\n",
      "Epoch 178/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6918 - val_accuracy: 0.5844\n",
      "Epoch 179/256\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6903 - val_accuracy: 0.5844\n",
      "Epoch 180/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6913 - val_accuracy: 0.5844\n",
      "Epoch 181/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6910 - val_accuracy: 0.5844\n",
      "Epoch 182/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6895 - val_accuracy: 0.5844\n",
      "Epoch 183/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 184/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6901 - val_accuracy: 0.5844\n",
      "Epoch 185/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6890 - val_accuracy: 0.5844\n",
      "Epoch 186/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6880 - val_accuracy: 0.5844\n",
      "Epoch 187/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6870 - val_accuracy: 0.5844\n",
      "Epoch 188/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6880 - val_accuracy: 0.5844\n",
      "Epoch 189/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6876 - val_accuracy: 0.5844\n",
      "Epoch 190/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6877 - val_accuracy: 0.5844\n",
      "Epoch 191/256\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6887 - val_accuracy: 0.5844\n",
      "Epoch 192/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6878 - val_accuracy: 0.5844\n",
      "Epoch 193/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6892 - val_accuracy: 0.5844\n",
      "Epoch 194/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6877 - val_accuracy: 0.5844\n",
      "Epoch 195/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6871 - val_accuracy: 0.5844\n",
      "Epoch 196/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6877 - val_accuracy: 0.5844\n",
      "Epoch 197/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6900 - val_accuracy: 0.5844\n",
      "Epoch 198/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6464 - accuracy: 0.6531 - val_loss: 0.6872 - val_accuracy: 0.5844\n",
      "Epoch 199/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6901 - val_accuracy: 0.5844\n",
      "Epoch 200/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6886 - val_accuracy: 0.5844\n",
      "Epoch 201/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6888 - val_accuracy: 0.5844\n",
      "Epoch 202/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6897 - val_accuracy: 0.5844\n",
      "Epoch 203/256\n",
      "20/20 [==============================] - 0s 14ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6885 - val_accuracy: 0.5844\n",
      "Epoch 204/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6873 - val_accuracy: 0.5844\n",
      "Epoch 205/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6871 - val_accuracy: 0.5844\n",
      "Epoch 206/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6884 - val_accuracy: 0.5844\n",
      "Epoch 207/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6885 - val_accuracy: 0.5844\n",
      "Epoch 208/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 209/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6876 - val_accuracy: 0.5844\n",
      "Epoch 210/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6879 - val_accuracy: 0.5844\n",
      "Epoch 211/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6461 - accuracy: 0.6531 - val_loss: 0.6906 - val_accuracy: 0.5844\n",
      "Epoch 212/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6903 - val_accuracy: 0.5844\n",
      "Epoch 213/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6903 - val_accuracy: 0.5844\n",
      "Epoch 214/256\n",
      "20/20 [==============================] - 0s 12ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6910 - val_accuracy: 0.5844\n",
      "Epoch 215/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6898 - val_accuracy: 0.5844\n",
      "Epoch 216/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6461 - accuracy: 0.6531 - val_loss: 0.6917 - val_accuracy: 0.5844\n",
      "Epoch 217/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6898 - val_accuracy: 0.5844\n",
      "Epoch 218/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6904 - val_accuracy: 0.5844\n",
      "Epoch 219/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6913 - val_accuracy: 0.5844\n",
      "Epoch 220/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6454 - accuracy: 0.6531 - val_loss: 0.6888 - val_accuracy: 0.5844\n",
      "Epoch 221/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6872 - val_accuracy: 0.5844\n",
      "Epoch 222/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6865 - val_accuracy: 0.5844\n",
      "Epoch 223/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6880 - val_accuracy: 0.5844\n",
      "Epoch 224/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6878 - val_accuracy: 0.5844\n",
      "Epoch 225/256\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6886 - val_accuracy: 0.5844\n",
      "Epoch 226/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6888 - val_accuracy: 0.5844\n",
      "Epoch 227/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6897 - val_accuracy: 0.5844\n",
      "Epoch 228/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6893 - val_accuracy: 0.5844\n",
      "Epoch 229/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6865 - val_accuracy: 0.5844\n",
      "Epoch 230/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6864 - val_accuracy: 0.5844\n",
      "Epoch 231/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6868 - val_accuracy: 0.5844\n",
      "Epoch 232/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6878 - val_accuracy: 0.5844\n",
      "Epoch 233/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 234/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6906 - val_accuracy: 0.5844\n",
      "Epoch 235/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6887 - val_accuracy: 0.5844\n",
      "Epoch 236/256\n",
      "20/20 [==============================] - 0s 15ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6882 - val_accuracy: 0.5844\n",
      "Epoch 237/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6909 - val_accuracy: 0.5844\n",
      "Epoch 238/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6458 - accuracy: 0.6531 - val_loss: 0.6915 - val_accuracy: 0.5844\n",
      "Epoch 239/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6910 - val_accuracy: 0.5844\n",
      "Epoch 240/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6894 - val_accuracy: 0.5844\n",
      "Epoch 241/256\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6897 - val_accuracy: 0.5844\n",
      "Epoch 242/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6904 - val_accuracy: 0.5844\n",
      "Epoch 243/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6891 - val_accuracy: 0.5844\n",
      "Epoch 244/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6455 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 245/256\n",
      "20/20 [==============================] - 0s 11ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6896 - val_accuracy: 0.5844\n",
      "Epoch 246/256\n",
      "20/20 [==============================] - 0s 13ms/step - loss: 0.6459 - accuracy: 0.6531 - val_loss: 0.6874 - val_accuracy: 0.5844\n",
      "Epoch 247/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6869 - val_accuracy: 0.5844\n",
      "Epoch 248/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6883 - val_accuracy: 0.5844\n",
      "Epoch 249/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6875 - val_accuracy: 0.5844\n",
      "Epoch 250/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6868 - val_accuracy: 0.5844\n",
      "Epoch 251/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6871 - val_accuracy: 0.5844\n",
      "Epoch 252/256\n",
      "20/20 [==============================] - 0s 10ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6879 - val_accuracy: 0.5844\n",
      "Epoch 253/256\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6890 - val_accuracy: 0.5844\n",
      "Epoch 254/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6457 - accuracy: 0.6531 - val_loss: 0.6887 - val_accuracy: 0.5844\n",
      "Epoch 255/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6904 - val_accuracy: 0.5844\n",
      "Epoch 256/256\n",
      "20/20 [==============================] - 0s 9ms/step - loss: 0.6456 - accuracy: 0.6531 - val_loss: 0.6892 - val_accuracy: 0.5844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x217b45c18d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model.fit(train_data, train_labels, epochs=256,verbose=1,validation_data=(val_data,val_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e34d73ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 0.6149 - accuracy: 0.7013\n",
      "Test accuracy: 0.701298713684082\n",
      "Test Loss: 0.6148750185966492\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print('Test accuracy:', test_acc)\n",
    "print('Test Loss:',test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b544364a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n",
      "[[0.5256994]]\n",
      "The person is diabetic\n"
     ]
    }
   ],
   "source": [
    "input_data = (5,166,72,19,175,25.8,0.587,51)\n",
    "\n",
    "# changing the input_data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] < 0.5):\n",
    "  print('The person is not diabetic')\n",
    "else:\n",
    "  print('The person is diabetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9a4555e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdcf548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'diabetes_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e315063a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open('diabetes_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf68b598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 94ms/step\n",
      "[[0.52745056]]\n",
      "The person is diabetic\n"
     ]
    }
   ],
   "source": [
    "input_data = (5,166,72,19,175,25.8,0.587,51)\n",
    "\n",
    "# changing the input_data to numpy array\n",
    "input_data_as_numpy_array = np.asarray(input_data)\n",
    "\n",
    "# reshape the array as we are predicting for one instance\n",
    "input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)\n",
    "\n",
    "prediction = loaded_model.predict(input_data_reshaped)\n",
    "print(prediction)\n",
    "\n",
    "if (prediction[0] < 0.5):\n",
    "  print('The person is not diabetic')\n",
    "else:\n",
    "  print('The person is diabetic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ca5c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
